#!/usr/bin/env python
#
# reposurgeon - a repository surgeon.
#
# By ESR, October 2010.  BSD terms apply.
#
# Requires Python 2.5 or newer.
#
import sys, os, getopt, cStringIO, cmd, tempfile, subprocess
import readline, time, calendar, re, signal, shutil, copy, shlex
import email.message, email.parser, email.utils

version="0.7"

#
# This code is intended to be hackable to support for special-purpose or
# custom operations, though it's even better if you ca come up with a new
# surgical primitive general enough to ship with the stock version.  For
# either case, here's a guide to the architecture.
#
# The core classes are largely about deserializing and reserializing import
# streams.  In between these two operations the repo state lives in a
# fairly simple Python object, Repository. The main part of Repository
# is just a list of events - Commits, Blobs, Tags, Resets, and Passthroughs.
# These are straightforward representations of the command types in an
# import stream, with Passthrough as a way of losslessly conveying lines
# the parser does not recognize.
#
#  +-------------+    +---------+    +-------------+
#  | Deserialize |--->| Operate |--->| Reserialize |
#  +-------------+    +---------+    +-------------+
#
# The general theory of reposurgeon is: you deserialize, you do stuff
# to the event list that preserves correctness invariants, you
# reserialize.  The "do stuff" is mostly not in the core classes, but
# there is one exception.  The primitive to delete a commit and
# shuffle its fileops forwards is seriously intertwined with the core
# classes and actually makes up almost 50% of Repository by line count.
#
# The rest of the surgical code lives outside the core classes. Most of it
# lives in the RepoSurgeon class, the command interpreter.  (This may change
# in the future; that's an uncomfortably large lump of code.)
#
# In designing new commands for the interpreter, try hard to keep them
# orthogonal to the selection-set code. As often as piossible, commands
# should all have a similar form with a (single) selection set argument.
#
# VCS is not a core class.  The code for manipulating actual repos is bolted
# on the the ends of the pipeline, like this:
#
#  +--------+    +-------------+    +---------+    +-------------+    +--------+
#  | Import |--->| Deserialize |--->| Operate |--->| Deserialize |--->| Export |
#  +--------+    +-------------+    +---------+    +-------------+    +--------+
#
# The Import and Export boxes call methods in VCS.

class VCS:
    "Class representing a version-control system."
    def __init__(self, name,
                 subdirectory,
                 exporter,
                 styleflags,
                 initializer,
                 importer,
                 checkout):
        self.name = name
        self.subdirectory = subdirectory
        self.exporter = exporter
        self.styleflags = styleflags
        self.initializer = initializer
        self.importer = importer
        self.checkout = checkout
    def __repr__(self):
        return "Subdirectory: " + self.subdirectory + "\n" \
             + "    Exporter: " + self.exporter + "\n" \
             + "Export-Style: " + `self.styleflags` + "\n" \
             + " Initializer: " + self.initializer + "\n" \
             + "    Importer: " + self.importer + "\n" \
             + "    Checkout: " + self.checkout + "\n"

# All knowledge about specific version-control systems lives in the
# following class list.  The members are, respectively:
#
# * Name of its characteristic subdirectory.
# * Command to export from the VCS to the interchange format
# * Export-style flags.
#     "nl-after-commit" = inserts an extra NL after each commit
#     "nl-after-comment" = inserts an extra NL after each comment
#     "export-progress" = exporter generates its own progress messages,
#                         no need for baton prompt.
# * Command to initialize a new repo
# * Command to import from the interchange format
# * Command to check out working copies of the repo files.
#
# Note that some of the commands used here are plugins or extensions
# that are not part of the basic VCS. Thus these may fail when called;
# we need to be prepared to cope with that.
#
# %(tempfile)s in a command gets substituted with the name of a
# tempile that the calling code will know to read or write from as
# appropriate after the command is done.  If your exporter can simply
# dump to stdout, or your importer reasd from stdin, leave out the
# %(tempfile)s; reposurgeon will popen(3) the command, and it will
# actually be slightly faster (especially on large repos) because it
# won't have to wait for the tempfile I/O to complete.
#
# %(basename) is replaced with the basename of the repo directory.
#
# Subversion/RCS/CVS aren't in this table because exporting from them
# requires fixups of usernames in the committer information to full
# email addresses.  Trying to handle that entirely inside this tool
# would be excessively messy, so we don't. Instead we let the user
# transform dump files and cope with the export/import himself.
#
vcstypes = [
    VCS(name="git",
        subdirectory=".git",
        exporter="git fast-export -M -C --signed-tags=verbatim --tag-of-filtered-object=drop --all",
        styleflags=("nl-after-commit",),
        initializer="git init",
        importer="git fast-import",
        checkout="git checkout"),
    # The bzr import/export methods require the bzr-fast-import plugin.
    VCS(name="bzr",
        subdirectory=".bzr",
        exporter="bzr fast-export --no-plain %(basename)s",
        styleflags=("export-progress", "nl-after-comment",),
        initializer=None,
        importer="bzr fast-import -",
        checkout="bzr checkout"),
    # The hg export-import methods are not part of stock hg
    # Export is tested and works; import is flaky.
    VCS(name="hg",
        subdirectory=".hg",
        exporter="hg-fast-export.py --marks /dev/null --mapping /dev/null --heads /dev/null --status /dev/null --repo .",
        styleflags=("nl-after-comment", "nl-after-commit", "export-progress"),
        initializer="hg init",
        importer="hg fastimport %(tempfile)s",
        checkout="hg checkout"),
    ]

verbose         = 0
DEBUG_SHUFFLE   = 2    # Debug directory handling
DEBUG_DELETE    = 2    # Debug canonicalization after deletes
DEBUG_COMMANDS  = 2    # Show commands as they are executed
DEBUG_EMAILIN   = 3    # Debug event round-tripping through mailbox_{out|in} 
DEBUG_MERGE     = 3    # Debug mark assignments in merging
DEBUG_LEXER     = 4    # Debug selection-language parsing

def screenwidth():
    "Return the current width of the terminal window."
    with popen_or_die('stty size', 'r') as tp:
        return int(tp.read().split()[1])

def nuke(directory, legend):
    "Remove a (large) directory, with a progress indicator."
    with Baton(legend, enable=verbose>=DEBUG_SHUFFLE) as baton:
        for root, dirs, files in os.walk(directory, topdown=False):
            for name in files:
                os.remove(os.path.join(root, name))
                baton.twirl()
            for name in dirs:
                os.rmdir(os.path.join(root, name))
                baton.twirl()
    try:
        os.rmdir(directory)
    except OSError:
        pass

class Baton:
    "Ship progress indications to stdout."
    def __init__(self, prompt, endmsg='done', enable=False):
        self.prompt = prompt
        self.endmsg = endmsg
        if enable:
            self.stream = sys.stdout
        else:
            self.stream = None
    def __enter__(self):
        if self.stream:
            self.stream.write(self.prompt + "...")
            if os.isatty(self.stream.fileno()):
                self.stream.write(" \010")
            self.stream.flush()
        self.count = 0
        self.time = time.time()
        return self
    def twirl(self, ch=None):
        if self.stream is None:
            return
        if os.isatty(self.stream.fileno()):
            if ch:
                self.stream.write(ch)
            else:
                self.stream.write("-/|\\"[self.count % 4])
                self.stream.write("\010")
            self.stream.flush()
        self.count = self.count + 1
        return
    def __exit__(self, extype, value, traceback):
        if extype == KeyboardInterrupt:
            self.endmsg = "interrupted"
        if extype == FatalException:
            self.endmsg = "aborted by error"
        if self.stream:
            self.stream.write("...(%2.2f sec) %s.\n" \
                              % (time.time() - self.time, self.endmsg))
        return False

class RepoSurgeonEmail(email.message.Message):
    "Specialized email message with a distinguishing starter."
    def __init__(self, **kwargs):
        email.message.Message.__init__(self, **kwargs)        
        self.set_unixfrom(78 * "-")
    @staticmethod
    def readmsg(fp):
        msg = ''
        firstline = fp.readline()
        if not firstline:
            return None
        elif not firstline.startswith(78 * "-"):
            msg = firstline
        while True:
            line = fp.readline()
            if not line:
                break
            if line.startswith(78 * "-"):
                break
            msg += line
        return msg
    def __str__(self):
        return email.message.Message.__str__(self).replace("\n--", "\n.--")

class Date:
    "A time/date in local time. Preserves TZ information but doesn't use it."
    def __init__(self, text):
        "Recognize date formats that exporters or email programs might emit."
        # First, look for git's preferred format.
        text = text.strip() 
        if re.match(r"[0-9]+\s*[+-][0-9]+$", text):
            (self.timestamp, self.timezone) = text.split()
            self.timestamp = int(self.timestamp)
            return
        # If that didn't work, look for an RFC822 date, which git also
        # accepts. Note, there could be edge cases that Python's parser
        # handles but git doesn't.
        try:
            self.timestamp = int(time.mktime(email.utils.parsedate(text)))
            self.timezone = text.split()[5]
            return
        except TypeError:
            # time.mktime throws this when it gets None:
            # TypeError: argument must be 9-item sequence, not None
            pass
        # Also accept IS8601 dates in Zulu time, just because I like them.
        try:
            iso860date = time.strptime(text, "%Y-%m-%dT%H:%M:%SZ")
            self.timestamp = calendar.timegm(iso860date)
            self.timezone = "+0000"
            return
        except ValueError:
            # time.strptime() throws this
            # "time data 'XXXX' does not match format '%Y-%m-%dT%H:%M:%S'" 
            pass
        # Date format not recognized
        raise FatalException("'%s' is not a valid timestamp" % text)
    def iso8601(self):
        "Format as an ISO8601 timestamp."
        return time.strftime("%Y-%m-%dT%H:%M:%S", time.localtime(self.timestamp)) + self.timezone
    def rfc822(self):
        "Format as an RFC822 timestamp."
        return time.strftime("%a %d %b %Y %H:%M:%S", time.localtime(self.timestamp)) + " " + self.timezone
    def delta(self, other):
        return other.timestamp - self.timestamp
    def __str__(self):
        "Format as a git timestamp."
        return str(self.timestamp) + " " + self.timezone
    def __cmp__(self, other):
        return cmp(self.timestamp, other.timestamp)

class Attribution:
    "Represents an attribution of a repo action to a person and time."
    def __init__(self, person=None):
        self.name = self.email = self.date = None
        if person:
            # First, validity-check the email address
            (self.name, self.email) = email.utils.parseaddr(person)
            if not self.name or not self.email:
                raise FatalException("can't recognize address in attribution")
            # Attribution format is actually stricter than RFC822;
            # needs to have a following date in the right place.
            person = person.replace(" <", "|").replace("> ", "|")
            try:
                self.date = Date(person.strip().split("|")[2])
            except (ValueError, IndexError):
                raise FatalException("malformed attribution %s" % person)
    def email_out(self, msg, hdr):
        "Update an RC822 message object with a representation of this."
        msg[hdr] = self.name + " <" + self.email + ">"
        msg[hdr + "-Date"] = self.date.rfc822()
    def __eq__(self, other):
        "Compare attributions after canonicalization."
        return (self.name == other.name
                and self.email == other.email
                and self.date == other.date)
    def __str__(self):
        return self.name + " <" + self.email + "> " + str(self.date)

class Blob:
    "Represent a detached blob of data referenced by a mark."
    def __init__(self, repo):
        self.repo = repo
        self.mark = None
        self.path = None      # First in-repo path associated with this blob
        self.timestamp = None
        self.color = None
    def when(self):
        "Imputed timestamp for sorting after merges."
        return self.timestamp
    def blobfile(self):
        return self.repo.subdir() + "/blob-" + `id(self)`
    def release(self):
        os.remove(self.blobfile())
        self.path = None             # Marked for deletion
    def __str__(self):
        with open(self.blobfile()) as dp:
            content = dp.read()
        return "blob\nmark %s\ndata %d\n%s\n" % (self.mark, len(content), content)

class Tag:
    "Represents an annotated tag."
    def __init__(self, name, committish, tagger, content):
        self.name = name
        self.committish = committish
        self.tagger = tagger
        self.comment = content
        self.color = None
    def when(self):
        "Imputed timestamp for sorting after merges."
        return self.tagger.date.timestamp
    def email_out(self, eventnum):
        "Enable do_mailbox_out() to report these."
        msg = RepoSurgeonEmail()
        msg["Event-Number"] = str(eventnum+1)
        msg["Tag-Name"] = self.name
        if self.tagger:
            self.tagger.email_out(msg, "Tagger")
        msg.set_payload(self.comment)
        return str(msg)
    def email_in(self, msg):
        "Update this Tag from a parsed email message."
        if "Tag-Name" not in msg or "Tagger" not in msg:
            raise FatalException("update to tag %s is malformed" %
                                       self.name)
        modified = False
        newname = msg["Tag-Name"]
        if self.name != newname:
            if verbose >= DEBUG_EMAILIN:
                print >>sys.stderr,"reposurgeon: in tag %d, Tag-Name is modified %s -> %s" \
                      % (int(msg["Event-Number"]), `self.name`, `newname`)
            self.name = newname
            modified = True
        if "Tagger" in msg:
            (newname, newemail) = email.utils.parseaddr(msg["Tagger"])
            if not newname or not newemail:
                raise FatalException("can't recognize address in Tagger")
            else:
                if self.tagger.name != newname or self.tagger.email != newemail:
                    (self.tagger.name, self.tagger.email) = (newname, newemail)
                    if verbose >= DEBUG_EMAILIN:
                        print >>sys.stderr,"reposurgeon: in tag %d, Tagger is modified" \
                              % (int(msg["Event-Number"]))
                    modified = True
            date = Date(msg["Tagger-Date"])
            if date != self.tagger.date:
                if verbose >= DEBUG_EMAILIN:
                    print >>sys.stderr,"reposurgeon: in event %d, Tagger-Date is modified '%s' -> '%s' (delta %d)" \
                          % (int(msg["Event-Number"]),
                             self.tagger.date, date,
                             self.tagger.date.delta(date))
                self.tagger.date = date
                modified = True
        newcomment = msg.get_payload().strip() + "\n"
        if newcomment != self.comment:
            if verbose >= DEBUG_EMAILIN:
                print >>sys.stderr,"reposurgeon: in tag %d, comment is modified '%s' -> '%s'" \
                      % (int(msg["Event-Number"]), `self.comment`, `newcomment`)
            modified = True
            self.comment = newcomment
        return modified
    def __str__(self):
        "Dump this tag in import-stream format."
        st = "tag %s\nfrom %s\n" % (self.name, self.committish)
        if self.tagger:
            st += "tagger %s\n" % self.tagger
        st += "data %d\n%s\n" % (len(self.comment), self.comment,)
        return st

class Reset:
    "Represents a branch creation."
    def __init__(self):
        self.ref = None
        self.committish = None
        self.timestamp = None
    def when(self):
        "Imputed timestamp for sorting after merges."
        return self.timestamp
    def __str__(self):
        "Dump this reset in import-stream format."
        st = "reset %s\n" % self.ref
        if self.committish:
            st += "from %s\n\n" % self.committish
        return st

class FileOp:
    "Represent a primitive operation on a file."
    modify_re = re.compile(r"(M) ([0-9]+) (\S+) (.*)")
    def __init__(self, opline, commit):
        self.commit = commit                 # Only used for debugging.
        if opline.startswith("M"):
            m = FileOp.modify_re.match(opline)
            if not m:
                raise FatalException("bad format of M line: %s" % `opline`)
            (self.op, self.mode, self.ref, self.path) = m.groups()
        elif opline[0] == "D":
            (self.op, self.path) = ("D", opline[2:].strip())
        elif opline[0] in ("R", "C"):
            (self.op, self.source, self.target) = shlex.split(opline)
        elif opline == "deleteall":
            self.op = "deleteall"
        else:
            raise FatalException("unexpected fileop %s while parsing" % opline)
    def paths(self):
        "Return the set of all paths touched by this file op."
        if self.op in ("M", "D"):
            return set([self.path])
        elif self.op in ("R", "C"):
            return set([self.source, self.target])
    def relevant(self, other):
        "Do two fileops touch the same file(s)?"
        if self.op == "deleteall" or other.op == "deleteall":
            return True
        else:
            return self.paths() & other.paths()
    def __str__(self):
        "Dump this fileop in import-stream format."
        if self.op == "M":
            st = " ".join((self.op, self.mode, self.ref)) + " "
            if len(self.path.split()) > 1:
                st += '"' + self.path + '"'
            else:
                st += self.path
            if self.ref == 'inline':
                with open(os.path.join(self.commit.repo.subdir(), self.copyname)) as fp:
                    content = fp.read()
                st += "\ndata %d\n%s" % (len(content), content)
        elif self.op in "D":
            st = "D "
            if len(self.path.split()) > 1:
                st += '"' + self.path + '"'
            else:
                st += self.path
        elif self.op in ("R", "C"):
            st = '%s "%s" "%s"' %  (self.op, self.source, self.target)
        elif self.op == "deleteall":
            st = self.op
        else:
            raise FatalException("unexpected fileop %s while writing" % opline)
        return st

class Commit:
    "Generic commit object."
    def __init__(self, repo):
        self.repo = repo
        self.mark = None             # Mark name of commit (may be None)
        self.authors = []            # Authors of commit
        self.committer = None        # Person responsible for committing it.
        self.comment = None          # Commit comment
        self.parent_marks = []            # List of parent nodes
        self.branch = None           # branch name
        self.fileops = []            # blob and file operation list
        self.properties = {}         # commit properties (extension)
        self.pushed_to = False       # Flagged for resolution after delete
        self.color = None
    def when(self):
        "Imputed timestamp for sorting after merges."
        return self.committer.date.timestamp
    def lister(self, eventnum, cols):
        "Enable do_list() to report these."
        topline = self.comment.split("\n")[0]
        return "%6d %s %-*s" % \
                      (eventnum+1, self.committer.date.iso8601()[:-5], cols-27, topline[:cols-27]) 
    def email_out(self, eventnum):
        "Enable do_mailbox_out() to report these."
        msg = RepoSurgeonEmail()
        msg["Event-Number"] = str(eventnum+1)
        if self.authors:
            self.authors[0].email_out(msg, "Author")
            for (i, coauthor) in enumerate(self.authors[1:]):
                coauthor.email_out(msg, "Author" + `2+i`)
        self.committer.email_out(msg, "Committer")
        empty_properties = []
        propkeys = self.properties.keys()
        propkeys.sort()
        for name in propkeys:
            value = self.properties[name]
            if value in (True, False):
                if value:
                    empty_properties.append(name)
            else:
                hdr = "-".join(map(lambda s: s.capitalize(), name.split("-")))
                msg["Property-" + hdr] = value
        if empty_properties:
            msg["Empty-Properties"] = ",".join(empty_properties)
        msg.set_payload(self.comment)
        return str(msg)
    def email_in(self, msg):
        "Update this commit from a parsed email message."
        if "Committer" not in msg or "Committer-Date" not in msg:
            idme = self.mark or "unmarked"
            raise FatalException("update to commit %s is malformed" % idme)
        modified = False
        (newname, newemail) = email.utils.parseaddr(msg["Committer"])
        if not newname or not newemail:
            raise FatalException("can't recognize address in Committer")
        else:
            if self.committer.name != newname or self.committer.email != newemail:
                (self.committer.name, self.committer.email) = (newname, newemail)
                if verbose >= DEBUG_EMAILIN:
                    print >>sys.stderr,"reposurgeon: in commit %d, Committer is modified" \
                          % (int(msg["Event-Number"]))
                modified = True
        date = Date(msg["Committer-Date"])
        if date != self.committer.date:
            if verbose >= DEBUG_EMAILIN:
                print >>sys.stderr,"reposurgeon: in event %d, Committer-Date is modified '%s' -> '%s' (delta %d)" \
                      % (int(msg["Event-Number"]),
                         self.committer.date, date,
                         self.committer.date.delta(date))
            self.committer.date = date
            modified = True
        if "Author" in msg:
            author_re = re.compile("Author[0-9]*:")
            authorkeys = filter(lambda s: author_re.match(s), msg.keys())
            # Potential minor bug here if > 10 authors;
            # lexicographic sort order doesn't match numeric
            authorkeys.sort()
            for i in range(len(authorkeys) - len(self.authors)):
                self.authors.append(Attribution())
            # Another potential minor bug: permuting the set of authors
            # will look like a modification, as old and new authors are
            # compaired pairwise rather than set equality being checked.
            # Possibly a feature if one things order is significant, but
            # I just did it this way because it was easier.
            for (i, hdr) in enumerate(authorkeys):
                (newname, newemail) = email.utils.parseaddr(msg[hdr])
                if not newname or not newemail:
                    raise FatalException("can't recognize address in %s" % hdr)
                else:
                    if self.authors[i].name != newname or self.authors[i].email != newemail:
                        (self.authors[i].name, self.authors[i].email) = (newname, newemail)
                        if verbose >= DEBUG_EMAILIN:
                            print >>sys.stderr,"reposurgeon: in commit %d, Author is modified" \
                                  % (int(msg["Event-Number"]))
                        modified = True
                date = Date(msg[hdr + "-Date"])
                if date != self.authors[i].date:
                    if verbose >= DEBUG_EMAILIN:
                        print >>sys.stderr,"reposurgeon: in event %d, %s-Date is modified" \
                              % (int(msg["Event-Number"]), hdr)
                    self.authors[i].date = date
                    modified = True
        newprops = {}
        for prophdr in filter(lambda s: s.startswith("Property-"), msg.keys()):
            propkey = prophdr[9:].lower()
            newprops[propkey] = msg[prophdr]
        if "Empty-Properties" in msg:
            for token in msg["Empty-Properties"].split(","):
                self.properties[token.strip()] = True
        modified |= (newprops != self.properties)
        self.properties = newprops
        newcomment = msg.get_payload().strip() + "\n"
        if newcomment != self.comment:
            if verbose >= DEBUG_EMAILIN:
                print >>sys.stderr,"reposurgeon: in commit %d, comment is modified '%s' -> '%s'" \
                      % (int(msg["Event-Number"]), `self.comment`, `newcomment`)
            modified = True
            self.comment = newcomment
        return modified
    def children(self):
        "Get a list of this commit's children."
        return filter(lambda e:self.mark in e.parent_marks,self.repo.commits()) 
    def parents(self):
        "Get a list of this commit's parents."
        return filter(lambda e:e.mark in self.parent_marks,self.repo.commits()) 
    def cliques(self):
        "Return a dictionary mapping filenames to associated M cliques."
        cliques = {}
        for (i, fileop) in enumerate(self.fileops):
            if fileop.op == "M":
                if fileop.path not in cliques:
                    cliques[fileop.path] = []
                cliques[fileop.path].append(i)
        return cliques
    def fileop_dump(self, i):
        "Dump file ops without data or inlines; used for debugging only."
        print "commit %d, mark %s:" % (i+1, self.mark)
        for (i, op) in enumerate(self.fileops):
            if op is not None:
                print "%d: %-20s" % (i, str(op))
    def __str__(self):
        "Dump this commit in import-stream format."
        st = "commit %s\n" % self.branch
        if self.mark:
            st += "mark %s\n" % self.mark
        if self.authors:
            for author in self.authors:
                st += "author %s\n" % author
        if self.committer:
            st += "committer %s\n" % self.committer
        st += "data %d\n%s" % (len(self.comment), self.comment) 
        if "nl-after-comment" in self.repo.export_style():
            st += "\n"
        if self.parent_marks:
            st += "from %s\n" % self.parent_marks[0]
        for ancestor in self.parent_marks[1:]:
            st += "merge %s\n" % self.parent_marks[0]
        propkeys = self.properties.keys()
        propkeys.sort()
        for name in propkeys:
            value = self.properties[name]
            if value in (True, False):
                if value:
                    st += "property %s\n" % name
            else:
                st += "property %s %d %s\n" % (name, len(value), value)
        for op in self.fileops:
            st += str(op) + "\n"
        if "nl-after-commit" in self.repo.export_style():
            st += "\n"
        return st

class Passthrough:
    "Represents a passthrough line."
    def __init__(self, line):
        self.text = line
        self.timestamp = None
        # These must always be at start of file, so make them sort oldest.
        if line.startswith("feature") or line.startswith("option"):
            self.timestamp = 0
    def email_out(self, eventnum):
        "Enable do_mailbox_out() to report these."
        msg = RepoSurgeonEmail()
        msg["Event-Number"] = str(eventnum+1)
        msg.set_payload(self.text)
        return str(msg)
    def email_in(self, msg):
        self.text = msg.get_payload()
    def when(self):
        "Imputed timestamp for sorting after merges."
        return self.timestamp
    def __str__(self):
        "Dump this passthrough in import-stream format."
        return self.text

class FatalException:
    "Unrecoverable error."
    def __init__(self, msg):
        self.msg = msg

class Repository:
    "Generic repository object."
    def __init__(self):
        self.name = None
        self.readtime = None
        self.readsize = 0
        self.vcs = None
        self.sourcedir = None
        self.events = []    # A list of the events encountered, in order
        self.nmarks = 0
        self.branches = set([])
        self.import_line = 0
        self.preserve_set = set([])
        self.case_coverage = set([])
        self.basedir = os.getcwd()
    def cleanup(self):
        "Release blob files associated with this repo."
        nuke(self.subdir(), "reposurgeon: cleaning up %s" % self.subdir())
    def subdir(self, name=None):
        if name is None:
            name = self.name
        if not name:
            return os.path.join(self.basedir, ".rs" + `os.getpid()`)
        else:
            return os.path.join(self.basedir, ".rs" + `os.getpid()`+ "-" + name) 
    def error(self, msg, atline=True):
        "Throw fatal error during parsing."
        if atline:
            raise FatalException(msg + " at line " + `self.import_line`)
        else:
            raise FatalException(msg)
    def warn(self, msg, atline=True):
        "Display a parse warning."
        if atline and self.import_line:
            print "reposurgeon: " + msg + " at line " + `self.import_line`
        else:
            print "reposurgeon: " + msg
    def find(self, mark):
        "Find an object by mark"
        for (i, e) in enumerate(self.events):
            if hasattr(e, "mark") and mark == e.mark:
                return i
        return None
    def fast_import(self, fp, progress=False):
        "Initialize repo object from fast-import stream."
        try:
            try:
                if verbose >= DEBUG_SHUFFLE:
                    self.warn("repository fast import creates " + self.subdir())
                os.mkdir(self.subdir())
            except OSError:
                self.error("can't create operating directory", atline=False)
            with Baton("reposurgeon: from %s" % os.path.relpath(fp.name), enable=progress) as baton:
                self.import_line = 0
                linebuffers = []
                ncommits = 0
                def read_data(dp, line=None):
                    if not line:
                        line = readline()
                    if line.startswith("data <<"):
                        delim = line[7:]
                        while True:
                            dataline = fp.readline()
                            if dataline == delim:
                                break
                            elif not dataline:
                                raise FatalException("EOF while reading blob")
                    elif line.startswith("data"):
                        try:
                            count = int(line[5:])
                            dp.write(fp.read(count))
                        except ValueError:
                            self.error("bad count in data")
                    else:
                        self.error("malformed data header %s" % `line`)
                    line = readline()
                    if line != '\n':
                        pushback(line) # Data commands optionally end with LF
                    return dp
                def readline():
                    if linebuffers:
                        line = linebuffers.pop()
                    else:
                        self.import_line += 1
                        line = fp.readline()
                        self.readsize += len(line)
                    return line
                def pushback(line):
                    linebuffers.append(line)
                while True:
                    line = readline()
                    if not line:
                        break
                    elif not line.strip():
                        continue
                    elif line.startswith("blob"):
                        blob = Blob(self)
                        line = readline()
                        if line.startswith("mark"):
                            blob.mark = line[5:].strip()
                            read_data(open(blob.blobfile(), "w")).close()
                            self.nmarks += 1
                        else:
                            self.error("missing mark after blob")
                        self.events.append(blob)
                        baton.twirl()
                    elif line.startswith("data"):
                        self.error("unexpected data object")
                    elif line.startswith("commit"):
                        commitbegin = self.import_line
                        commit = Commit(self)
                        commit.branch = line.split()[1]
                        self.branches.add(commit.branch)
                        ncommits += 1
                        while True:
                            line = readline()
                            if not line:
                                break
                            elif line.startswith("mark"):
                                commit.mark = line[5:].strip()
                                self.nmarks += 1
                            elif line.startswith("author"):
                                try:
                                    commit.authors.append(Attribution(line[7:]))
                                except ValueError:
                                    self.error("malformed author line")
                            elif line.startswith("committer"):
                                try:
                                    commit.committer = Attribution(line[10:])
                                except ValueError:
                                    self.error("malformed committer line")
                            elif line.startswith("property"):
                                fields = line.split(" ")
                                if len(fields) < 3:
                                    self.error("malformed property line")
                                elif len(fields) == 3:
                                    self.properties[fields[1]] = True
                                else:
                                    name = fields[1]
                                    length = int(fields[2])
                                    value = " ".join(fields[3:])
                                    if len(value) < length:
                                        value += fp.read(length-len(value))
                                        if fp.read(1) != '\n':
                                            self.error("trailing junk on property value")
                                    elif len(value) == length + 1:
                                        value = value[:-1] # Trim '\n'
                                    else:
                                        self.error("garbage length field on property line")
                                    commit.properties[name] = value
                            elif line.startswith("data"):
                                dp = read_data(cStringIO.StringIO(), line)
                                commit.comment = dp.getvalue()
                                dp.close()
                            elif line.startswith("from") or line.startswith("merge"):
                                commit.parent_marks.append(line.split()[1])
                            # Handling of file ops begins.
                            elif line[0] in ("C", "D", "R"):
                                commit.fileops.append(FileOp(line, commit))
                            elif line == "filedeleteall\n":
                                commit.fileops.append(FileOp("filedeleteall"), commit)
                            elif line[0] == "M":
                                fileop = FileOp(line, commit)
                                if commit.mark is None:
                                    self.warn("unmarked commit")
                                commit.fileops.append(fileop)
                                if fileop.mode == "160000":
                                    # This is a submodule link.  The ref
                                    # field is a SHA1 hash and the path
                                    # is an external reference name.
                                    # Don't try to collect data, just pass
                                    # it through.
                                    pass
                                elif fileop.ref[0] == ':':
                                    for obj in self.events:
                                        if isinstance(obj, Blob) and obj.mark == fileop.ref:
                                            obj.path = fileop.path
                                            fileop.copyname = obj.blobfile()
                                            # This is a blatant hack.
                                            # We need to impute a timestamp
                                            # to each blob for sorting after
                                            # merge operations. We want the
                                            # blobs to tuck in close behind
                                            # their first associated commits.
                                            # So we do this and trust the
                                            # stability of Python sort
                                            # (guaranteed since Python 2.4).
                                            if obj.timestamp is None:
                                                obj.timestamp = commit.when()-1
                                            break
                                    else:
                                        self.error("no blob matches commit reference to %s" % fileop.ref)
                                elif fileop.ref == 'inline':
                                    fileop.copyname = "inline-%s" % `id(commit)`
                                    read_data(open(os.path.join(self.subdir(), fileop.copyname), "w")).close()
                                else:
                                    self.error("unknown content type in filemodify")
                            # Handling of file ops ends.
                            elif line.isspace():
                                # This handles slightly broken
                                # exporters like the bzr-fast-export
                                # one that may tack an extra LF onto
                                # the end of data objects.  With it,
                                # we don't drop out of the
                                # commit-processing loop until we see
                                # a *nonblank* line that doesn't match
                                # a commit subpart.
                                continue
                            else:
                                # Dodgy bzr autodetection hook...
                                if not self.vcs:
                                    if "branch-nick" in commit.properties:
                                        for vcs in vcstypes:
                                            if vcs.name == "bzr":
                                                self.vcs = vcs
                                                break
                                pushback(line)
                                break
                        if not (commit.mark and commit.committer):
                            self.import_line = commitbegin
                            self.error("missing required fields in commit")
                        self.events.append(commit)
                        baton.twirl()
                    elif line.startswith("reset"):
                        reset = Reset()
                        reset.ref = line[6:].strip()
                        line = readline()
                        if line.startswith("from"):
                            reset.committish = line[5:].strip()
                        else:
                            pushback(line)
                        self.events.append(reset)
                        baton.twirl()
                    elif line.startswith("tag"):
                        tagger = None
                        tagname = line[4:].strip()
                        line = readline()
                        if line.startswith("from"):
                            referent = line[5:].strip()
                        else:
                            self.error("missing from after tag")
                        line = readline()
                        if line.startswith("tagger"):
                            try:
                                tagger = Attribution(line[7:])
                            except ValueError:
                                self.error("malformed tagger line")
                        else:
                            self.warn("missing tagger after from in tag")
                            pushback(line)
                        dp = read_data(cStringIO.StringIO())
                        self.events.append(Tag(tagname,
                                               referent, tagger, dp.getvalue()))
                        baton.twirl()
                    else:
                        # Simply pass through any line we don't understand.
                        self.events.append(Passthrough(line))
                self.import_line = 0
            self.readtime = time.time()
            # Patch Reset timestamps in case this repo is ever merged.
            # This is another blatant hack. Try to keep them immediately 
            # after things they refer to.
            for (s, sevent) in enumerate(self.events):
                if isinstance(sevent, Reset):
                    if sevent.committish:
                        for tevent in self.events:
                            if isinstance(tevent, Commit):
                                if tevent.mark == sevent.committish:
                                    sevent.timestamp = tevent.when() + 1
                                    break
                    else:
                        for tevent in self.events:
                            if isinstance(tevent, Commit):
                                if tevent.branch == sevent.ref:
                                    sevent.timestamp = tevent.when() - 1
                                    break
                # Tuck Passthroughs right behind the first following commit 
                elif isinstance(sevent, Passthrough) and sevent.timestamp != 0: 
                    for (t, tevent) in enumerate(self.events):
                        if isinstance(tevent, Commit) and t > s:
                            sevent.timestamp = tevent.when() - 1
                            break
        except KeyboardInterrupt:
            nuke(self.subdir(), "reposurgeon: import interrupted, removing %s" % self.subdir())
            raise KeyboardInterrupt
    def export_style(self):
        "How should we tune the export dump format?"
        if self.vcs:
            return self.vcs.styleflags
        else:
            # Default to git style
            return ("nl-after-commit",)
    def fast_export(self, selection, fp, progress=False):
        "Dump the repo object in fast-export format."
        with Baton("reposurgeon: exporting", enable=progress) as baton:
            for ei in selection:
                baton.twirl()
                fp.write(str(self.events[ei]))
    def preserve(self, filename):
        "Add a path to the preserve set, to be copied back on rebuild."
        if os.path.exists(filename):
            self.preserve_set.add(filename)
        else:
            self.error("%s doesn't exist" % filename, atline=False)
    def unpreserve(self, filename):
        "Remove a path from the preserve set."
        if filename in self.preserve_set:
            self.preserve_set.remove(filename)
        else:
            self.error("%s doesn't exist" % filename, atline=False)
    def preservable(self):
        "Return the repo's preserve set."
        return self.preserve_set
    def rename(self, newname):
        "Rename the repo."
        try:
            # Can fail if the target directory exists.
            if verbose >= DEBUG_SHUFFLE:
                self.warn("repository rename calls os.rename(%s, %s)" % (`self.subdir()`, `self.subdir(newname)`))
            os.rename(self.subdir(), self.subdir(newname))
            self.name = newname
            for event in self.events:
                if isinstance(event, Blob):
                    event.subdir = os.path.abspath(self.subdir())
        except OSError, e:
            raise FatalException("repo rename %s -> %s failed"
                                       % (self.subdir(), self.subdir(newname)))
    def commits(self):
        "Return a list of the repository commit objects."
        return filter(lambda e: isinstance(e, Commit), self.events)
    def earliest(self):
        "Return the date of earlist commit."
        return self.commits()[0].committer.date
    #
    # Delete machinery begins here
    #
    def __ancestor_count(self, event, path):
        "Count modifications of a path in this commit and its ancestry chain."
        count = 0
        for fileop in event.fileops:
            if fileop.op == "M" and fileop.path == path:
                count = 1
                break
        return count + sum(map(lambda c: self.__ancestor_count(c, path), event.parents()))
    def __compose(self, event, left, right):
        "Compose two relevant fileops."
        # Here's what the fields in the return value mean:
        # 0: Was this a modification
        # 1: Op to replace the first with (None means delete)
        # 2: Op to replace the second with (None means delete)
        # 3: If not None, a warning to emit
        # 4: Case number, for coverage analysis
        pair = (left.op, right.op)
        #
        # First op M
        #
        if pair == ("M", "M"):
            # Leave these in place, they get handled later.
            return (False, left, right, None, 0)
        # M a + D a -> D a
        # Or, could reduce to nothing if M a was the only modify..
        elif left.op == "M" and right.op in "D":
            if self.__ancestor_count(event, left.path) == 1:
                return (True, None, None, None, 1)
            else:
                return (True, right, None, None, 2)
        elif left.op == "M" and right.op == "R":
            # M a + R a b -> R a b M b, so R falls towards start of list
            if left.path == right.source:
                if self.__ancestor_count(event, left.path) == 1:
                    # M a has no ancestors, preceding R can be dropped
                    left.path = right.target
                    return (True, left, None, None, 3)
                else:
                    # M a has ancestors, R is still needed
                    left.path = right.target
                    return (True, right, left, None, 4)
            # M b + R a b can't happen.  If you try to generate this with
            # git mv it throws an error.  An ordinary mv results in D b M a.
            elif left.path == right.target:
                return(True, right, None, "M followed by R to the M operand?", -1)
        # Correct reduction for this would be M a + C a b -> C a b + M a + M b,
        # that is we'd have to duplicate the modify. We'll leave it in place
        # for now.
        elif left.op == "M" and right.op == "C":
            return (False, left, right, None, 5)
        #
        # First op D or deleteall
        #
        # Delete followed by modify undoes delete, since M carries whole files. 
        elif pair == ("D", "M"):
            return (True, right, None, None, 6)
        # But we have to leave deletealls in place, since they affect right ops
        elif pair == ("deleteall", "M"):
            return (False, left, right, None, 7)
        # These cases should be impossible
        elif left.op == "deleteall" and right.op != "M":
            return (False, left, right,
                    "Non-M operation after deleteall?", -1)
        if left.op == "D" and right.op == "D":
            return (False, left, right, "Two Ds of %s?" % left.path, -2)
        if left.op == "D" and right.op in ("R", "C"):
            if left.path == right.source:
                return (False, left, right,
                        "R or C of %s after deletion?" % left.path, -3)
            else:
                return (False, left, right, None, 8)
        #
        # First op R
        #
        elif pair == ("R", "D"):
            if left.target == right.path:
                # Rename followed by delete of target composes to nothing
                return (True, None, None, None, 9)
            else:
                # On followed by delete of source discard the delete
                # but user should be warned. 
                return (False, left, None,
                        "delete of %s after renaming to %s?" % (right.path, left.source), -4)
        # Rename followed by deleteall shouldn't be possible
        elif pair == ("R", "deleteall") and left.target == right.path:
            return (False, None, right,
                    "rename before deleteall not removed?", -5)
        # Leave rename or copy followed by modify alone
        elif pair == ("R", "M") or pair == ("C", "M"):
            return (False, left, right, None, 10)
        # Compose renames where possible
        elif left.op == "R" and right.op == "R":
            if left.target == right.source:
                left.target = right.target
                return (True, source, None, None, 11)
            else:
                return (False, source, right,
                        "R %s %s is inconsistent with following operation" \
                        % (left.source, left.target), -6)
        # We could do R a b + C b c -> C a c + R a b, but why?
        if left.op == "R" and right.op == "C":
            return (False, left, right, None, 12)
        #
        # First op C
        #
        elif pair == ("C", "D"):
            if left.source == target.path:
                # Copy followed by delete of the source is a rename.
                left.op = "R"
                return (True, left, None, None, 13)
            elif left.target == target.path:
                # This delete undoes the copy
                return (True, None, None, None, 14)
        elif pair == ("C", "R"):
            if left.source == right.source:
                # No reduction
                return (False, left, right, None, 15)
            else:
                # Copy followed by a rename of the target reduces to single copy
                if left.target == right.source:
                    left.target = right.target
                    return (True, left, None, None, 16)
        elif pair == ("C", "C"):
            # No reduction
            return (False, left, right, None, 17)
        #
        # Case not covered
        #
        raise FatalException("can't compose op '%s' and '%s'" % (left, right))
    def canonicalize(self, ei):
        "Canonicalize the list of file operations in this commit."
        coverage = set([])
        commit = self.events[ei]
        # Handling deleteall operations is simple
        lastdeleteall = None
        for (i, a) in enumerate(commit.fileops):
            if a.op == "deleteall":
                lastdeleteall = i
        if lastdeleteall is not None:
            if verbose >= DEBUG_DELETE:
                print "reposurgeon: removing all before rightmost deleteall"
            commit.fileops = commit.fileops[lastdeleteall:]
        # Composition in the general case is trickier.
        while True:
            # Keep making passes until nothing mutates
            mutated = False
            for (i, a) in enumerate(commit.fileops):
                if a is None:
                    continue
                for (j, b) in enumerate(commit.fileops):
                    if b is None:
                        continue
                    if i < j and a.relevant(b):
                        (modified, newa, newb, warn, case) = self.__compose(commit, a, b)
                        if modified:
                            if verbose >= DEBUG_DELETE:
                                print "Reduction case %d fired on %s" % (case, (i,j))
                            mutated = True
                            commit.fileops[i] = newa
                            commit.fileops[j] = newb
                            if verbose >= DEBUG_DELETE:
                                print "During canonicalization:"
                                commit.fileop_dump(ei)
                            if warn:
                                self.warn(m, atline=False)
                            coverage.add(case)
            if not mutated:
                break
        commit.fileops = filter(lambda x: x is not None, commit.fileops)
        return coverage
    def delete(self, selected, policy):
        "Delete commits, handling multiple Ms on a file with specified policy"
        if not policy:
            policy = "complain"
        # Make sure we do deletions from greatest commit number to least
        selected = copy.copy(selected)
        selected.sort(lambda x, y: cmp(y, x))
        if verbose >= DEBUG_DELETE:
            print "Deletion list is %s" % map(lambda x: x+1, selected)
        # Here are the deletions
        for ei in selected:
            event = self.events[ei]
            if event.__class__ in (Reset, Tag, Passthrough):
                self.events.pop(d)
            elif isinstance(event, Blob):
                raise FatalException("attempt to directly delete blob")
            elif isinstance(event, Commit):
                if not event.children():
                    # Tip revision.  Release all its blobs.
                    for fileop in event.fileops:
                        if fileop.op == "M":
                            bi = self.find(fileop.ref)
                            assert(isinstance(self.events[bi], Blob))
                            self.events[bi].release()
                else:
                    for child in event.children():
                        # Reparent each child
                        child.parent_marks.remove(event.mark)
                        child.parent_marks += event.parent_marks
                        # Push a copy of the parent's file ops to it
                        # and mark it as needing resolution
                        for fileop in event.fileops:
                            fileop.commit = child
                        child.fileops = copy.copy(event.fileops) + child.fileops
                        child.pushed_to = True
                # Remove tags referring to this event. Its children will
                # still own the blobs, though they may be removed by
                # canonicalization.
                self.events = filter(lambda t: not (isinstance(t, Tag)
                                                    and t.committish == event.mark),
                                     self.events)
                # And remove it
                self.events.pop(ei)
            else:
                raise FatalException("unexpected object in event array")
        # Canonicalize all the commits that got ops pushed to them
        for (ei, event) in enumerate(self.events):
            if not isinstance(event, Commit):
                continue
            elif event.pushed_to:
                if verbose >= DEBUG_DELETE:
                    print "Before canonicalization:"
                    event.fileop_dump(ei)
                self.case_coverage |= self.canonicalize(ei)
                if verbose >= DEBUG_DELETE:
                    print "After canonicalization:"
                    event.fileop_dump(ei)
                # Now apply policy in the mutiple-M case
                for (path, oplist) in event.cliques().items():
                    if len(oplist) == 1:
                        continue
                    if not policy or policy == "complain" or verbose >= DEBUG_DELETE:
                        print >>sys.stderr,"reposurgeon: commit %d has multiple Ms for %s" % (i+1, path)
                    func = getattr(self, 'policy_' + policy)
                    func(event, oplist)
                    if verbose >= DEBUG_DELETE:
                        print "Commit %d, after applying policy:" % (ei +1,)
                        for op in event.fileops:
                            print str(op)
        # Clear everybody's problem flag
        for commit in self.commits():
            commit.pushed_to = False
    # Deletion policy hooks
    def policy_complain(self, commit, oplist):
        "Bitch but nothing else." 
        pass
    def policy_coalesce(self, commit, oplist):
        "Remove all but the last M."
        while len(oplist) > 1:
            commit.fileops.pop(oplist.pop(0))
    #
    # Delete machinery ends here
    #
    # Container emulation methods
    def __len__(self):
        return len(self.events)
    def __getitem__(self, i):
        return self.events[i]
    def __setitem__(self, i, v):
        self.events[i] = v

def complain(msg):
    print >>sys.stderr, "reposurgeon:", msg

def announce(msg):
    print "reposurgeon:", msg

def read_repo(source, preferred):
    "Read a repository using fast-import."
    if source == '-':
        repo = Repository()
        repo.fast_import(sys.stdin, progress=verbose>0)
    elif not os.path.exists(source):
        complain("%s does not exist" % source)
        return None
    elif not os.path.isdir(source):
        repo = Repository()
        repo.fast_import(open(source), progress=verbose>0)
    else:
        if verbose >= DEBUG_SHUFFLE:
            if preferred.name:
                announce("looking for a %s repo..." % preferred.name)
            else:
                announce("reposurgeon: looking for any repo...")
        hitcount = 0
        vcs = None
        for possible in vcstypes:
            if preferred and possible.name != preferred.name:
                continue
            subdir = os.path.join(source, possible.subdirectory)
            if os.path.exists(subdir) and os.path.isdir(subdir):
                vcs = possible
                hitcount += 1
        if hitcount == 0:
            complain("couldn't find a repo under %s" % os.path.relpath(source))
            return None
        elif hitcount > 1:
            complain("too many repos under %s" % os.path.relpath(source))
            return None
        elif verbose > 0:
            announce("found %s repository" % vcs.name)
        repo = Repository()
        repo.vcs = vcs
        repo.sourcedir = source
        showprogress = (verbose > 0) and not "export-progress" in repo.export_style()
        context = {"basename": os.path.basename(repo.sourcedir)}
        try:
            here = os.getcwd()
            os.chdir(repo.sourcedir)
            if "%(tempfile)s" in repo.vcs.exporter:
                try:
                    (tfdesc, tfname) = tempfile.mkstemp()
                    context["tempfile"] = tfname
                    do_or_die(repo.vcs.exporter % context, "repository export")
                    with open(tfname) as tp:
                        repo.fast_import(tp, progress=showprogress);
                finally:
                    os.remove(tfname)
            else:
                with popen_or_die(repo.vcs.exporter % context, "repository export") as tp:
                    repo.fast_import(tp, progress=showprogress);
        finally:
            os.chdir(here)
    return repo

class CriticalRegion:
    "Encapsulate operations to try and make us un-interruptible."
    # This number is magic. Python sets a much higher signal.NSIG
    # value, but under Linux the signal calls start to trigger
    # runtime errors at this value and above.
    NSIG = 32
    def __enter__(self):
        "Begin critical region."
        if verbose:
            complain("critical region begins...")
        # Alas that we lack sigblock support
        self.handlers = [None]*(CriticalRegion.NSIG+1)
        for sig in range(1, CriticalRegion.NSIG):
            if not sig in (signal.SIGKILL, signal.SIGSTOP):
                self.handlers[sig] = signal.signal(sig, signal.SIG_IGN)
    def __exit__(self, extype, value, traceback):
        "End critical region."
        for sig in range(1, CriticalRegion.NSIG):
            if not sig in (signal.SIGKILL, signal.SIGSTOP):
                signal.signal(sig, self.handlers[sig])
        if verbose:
            complain("critical region ends.")
        return False

def rebuild_repo(repo, target, preferred):
    "Rebuild a repository from the captured state."
    if not target and repo.sourcedir:
        target = repo.sourcedir
    if target:
        target = os.path.abspath(target)
    else:
        complain("no default destination for rebuild")
        return
    if not preferred and repo.vcs:
        preferred = repo.vcs
    if not preferred:
        complain("please prefer a repo type first")

    # Create a new empty directory to do the rebuild in
    staging = target + "-stage" + str(os.getpid())
    assert(os.path.isabs(target) and os.path.isabs(staging))
    try:
        os.mkdir(staging)
    except OSError:
        complain("staging directory creation failed")
        return
    # Try the rebuild in the empty staging directory 
    here = os.getcwd()
    try:
        os.chdir(staging)
        if preferred.initializer:
            do_or_die(preferred.initializer, "repository initialization")
        parameters = {"basename": os.path.basename(target)}
        if "%(tempfile)s" in preferred.importer:
            try:
                (tfdesc, tfname) = tempfile.mkstemp()
                with open(tfname, "w") as tp:
                    repo.fast_export(range(len(repo)), tp, progress=verbose>0)
                do_or_die(preferred.exporter % parameters, "import")
            finally:
                os.remove(tfname)
        else:
            with popen_or_die(preferred.importer % parameters, "import", mode="w") as tp:
                repo.fast_export(range(len(repo)), tp, progress=verbose>0)
        do_or_die(preferred.checkout, "repository_checkout")
        if verbose:
            announce("rebuild is complete.")

        os.chdir(here)
        # Rebuild succeeded - make an empty backup directory
        backupcount = 1
        while True:
            savedir = target + (".~%d~" % backupcount)
            if os.path.exists(savedir):
                backupcount += 1
            else:
                break
        os.mkdir(savedir)
        assert(os.path.abspath(savedir))

        # This is a critical region.  Ignore all signals until we're done.
        with CriticalRegion():
            # Move the unmodified repo contents in target to the
            # backup directory.  Then move the staging contents to the
            # target directory.  Finally, restore designated files
            # from backup to target.
            for sub in os.listdir(target):
                os.rename(os.path.join(target, sub),
                          os.path.join(savedir, sub))
            if verbose:
                announce("repo backed up to %s." % os.path.relpath(savedir))
            for sub in os.listdir(staging):
                os.rename(os.path.join(staging, sub),
                          os.path.join(target, sub))
            if verbose:
                announce("modified repo moved to %s." % os.path.relpath(target))
            if not repo.preserve_set:
                if verbose:
                    announce("no preservations.")
            else:
                for sub in repo.preserve_set:
                    src = os.path.join(savedir, sub)
                    dst = os.path.join(target, sub)
                    if os.path.isdir(src):
                        shutil.copytree(src, dst)
                    else:
                        shutil.copy2(src, dst)
                if verbose:
                    announce("preserved files restored.")
    finally:
        os.chdir(here)
        nuke(staging, "reposurgeon: removing staging directory")

def do_or_die(cmd, legend=""):
    "Either execute a command or raise a fatal exception."
    if legend:
        legend = " "  + legend
    if verbose >= DEBUG_COMMANDS:
        announce("executing '%s'%s" % (cmd, legend))
    try:
        retcode = subprocess.call(cmd, shell=True)
        if retcode < 0:
            raise FatalException("child was terminated by signal %d." % -retcode)
        elif retcode != 0:
            raise FatalException("child returned %d." % retcode)
    except (OSError, IOError), e:
        raise FatalException("execution of %s%s failed: %s" % (cmd, legend, e))

class popen_or_die:
    "Read or write from a subordinate process."
    def __init__(self, cmd, legend="", mode="r"):
        assert mode in ("r", "w")
        self.cmd = cmd
        self.legend = legend
        self.mode = mode
        if self.legend:
            self.legend = " "  + self.legend
    def __enter__(self):
        if verbose >= DEBUG_COMMANDS:
            if self.mode == "r":
                announce("reading from '%s'%s" % (self.cmd, self.legend))
            else:
                announce("writing to '%s'%s" % (self.cmd, self.legend))
        try:
            self.fp = os.popen(self.cmd, self.mode)
            return self.fp
        except (OSError, IOError), e:
            raise FatalException("execution of %s%s failed: %s" \
                                 % (self.cmd, self.legend, e))
    def __exit__(self, extype, value, traceback):
        if extype:
            if verbose:
                complain("exception %s in popen_or_die." % (extype,))
            raise extype, value, traceback
        if self.fp.close() is not None:
            legend = "%s%s returned error" % (self.cmd, self.legend)
            if extype == FatalException:
                value.msg += " and " + legend
            else:
                raise FatalException(legend + ".")
        return False

def iso8601_from_unixtime(secs_since_epoch):
    "Make an ISO8601 timestamp frm Unix time."
    return time.strftime("%Y-%m-%dT%H:%M:%S", time.localtime(secs_since_epoch))

class RecoverableException:
    def __init__(self, msg):
        self.msg = msg

class RepoSurgeon(cmd.Cmd):
    "Repository surgeon command interpreter."
    def __init__(self):
        cmd.Cmd.__init__(self)
        self.use_rawinput = True
        self.echo = 0
        self.prompt = "reposurgeon% "
        self.repo = None
        self.preferred = None
        self.selection = []
        self.name_to_repo = {}
        self.history = []
    #
    # Housekeeping hooks.
    #
    def onecmd(self, line):
        "Execute one command, fielding interrupts for recoverable exceptions."
        try:
            cmd.Cmd.onecmd(self, line)
        except RecoverableException, e:
            complain(e.msg)
    def postcmd(self, stop, line):
        if line == "EOF":
            return True
    def emptyline(self):
        pass
    def precmd(self, line):
        "Pre-command hook."
        self.history.append(line.rstrip())
        if self.echo:
            sys.stdout.write(line.rstrip()+"\n")
        if "#" in line:
            line = line[:line.index("#")].rstrip()
        return line
    def do_shell(self, line):
        "Execute a shell command."
        if os.system(line):
            raise RecoverableException("'shell %s' returned error." % line)
    def do_EOF(self, line):
        "Terminate reposurgeon."
        print ""
        return True
    def cleanup(self):
        "Tell all the repos we're holding to clean up."
        if verbose >= DEBUG_SHUFFLE:
            announce("interpreter cleanup called.")
        for repo in self.name_to_repo.values():
            repo.cleanup()
    #
    # The selection-language parsing code starts here.
    #
    def set_selection_set(self, line, default=None):
        "Implement object-selection syntax."
        # Returns the line with the selection removed
        self.selection = []
        if not self.repo:
            return line
        self.line = line
        self.selection = list(self.eval_expression())
        if self.line == line:
            self.selection = default
        else:
            self.selection.sort()
        return self.line
    def peek(self):
        return self.line and self.line[0]
    def pop(self):
        if not self.line:
            return ''
        else:
            c = self.line[0]
            self.line = self.line[1:]
            return c
    def push(c):
        self.line = c + self.line[0]
    def eval_expression(self):
        if verbose >= DEBUG_LEXER:
            print "eval_expression(%s)" % self.line
        self.line = self.line.lstrip()
        value = self.eval_disjunct()
        c = self.peek()
        if c and not c.isspace() and not c.isalpha() and not c in ('-', '+'):
            raise RecoverableException("trailing junk on selection: %s" % `self.line`)
        if verbose >= DEBUG_LEXER:
            print "%s <- eval_expression(), left = %s" % (value, `self.line`)
        return value
    def eval_disjunct(self):
        "Evaluate a disjunctive expression (| has lowest precedence)" 
        if verbose >= DEBUG_LEXER:
            print "eval_disjunct(%s)" % self.line
        self.line = self.line.lstrip()
        disjunct = set([])
        while True:
            conjunct = self.eval_conjunct()
            if conjunct is None:
                break
            else:
                disjunct |= conjunct
            self.line = self.line.lstrip()
            if self.peek() == '|':
                self.pop()
            else:
                break
        if verbose >= DEBUG_LEXER:
            print "%s <- eval_disjunct(), left = %s" % (disjunct, `self.line`)
        return disjunct
    def eval_conjunct(self):
        "Evaluate a conjunctive expression (& has higher precedence)" 
        if verbose >= DEBUG_LEXER:
            print "eval_conjunct(%s)" % self.line
        self.line = self.line.lstrip()
        conjunct = set(range(0, len(self.repo)))
        while True:
            term = self.eval_term()
            if term is None:
                break
            else:
                conjunct = conjunct & term
            self.line = self.line.lstrip()
            if self.peek() == '&':
                self.pop()
            else:
                break
        if verbose >= DEBUG_LEXER:
            print "%s <- eval_conjunct(), left = %s" % (conjunct, `self.line`)
        return conjunct
    def eval_term(self):
        if verbose >= DEBUG_LEXER:
            print "eval_term(%s)" % self.line
        self.line = self.line.lstrip()
        if self.peek() == '{':
            self.pop()
            term = self.eval_disjunct()
            self.line = self.line.lstrip()
            if self.peek() != '}':
                raise RecoverableException("trailing junk on inner expression")
            else:
                self.pop()
        else:
            term = self.eval_visibility()
            if term is None:
                term = self.eval_polyrange()
                if term is None:
                    term = self.eval_textsearch()
                    if term == None:
                        term = self.eval_branchset()
        if verbose >= DEBUG_LEXER:
            print "%s <- eval_term(), left = %s" % (term, `self.line`)
        return term
    def eval_visibility(self):
        "Parse a visibility spec."
        if verbose >= DEBUG_LEXER:
            print "eval_visibility(%s)" % self.line
        self.line = self.line.lstrip()
        if not self.peek() == "=":
            visibility = None
        else:
            typeletters = {
                "B" : Blob,
                "C" : Commit,
                "T" : Tag,
                "R" : Reset,
                "P" : Passthrough,
                }
            visible = set([])
            modmode = None
            self.pop()
            while self.peek() in tuple(typeletters.keys()):
                c = self.pop()
                if c in typeletters:
                    visible.add(typeletters[c])
            # We need a special check here because these expressions
            # could otherwise run onto the text part of the command.
            if self.peek() not in "()|& ":
                raise RecoverableException("garbled type mask at %s" % `self.line`)
            if verbose >= DEBUG_LEXER:
                print "reposurgeon: visibility set is %s with %s left" % (map(lambda x: x.__name__, visible), `self.line`)
            selected = []
            for (i, event) in enumerate(self.repo):
                if event.__class__ in visible:
                    selected.append(i)
            visibility = set(selected)
        if verbose >= DEBUG_LEXER:
            print "%s <- eval_visibility(), left = %s" % (visibility, `self.line`)
        return visibility
    def eval_polyrange(self):
        "Parse a polyrange specification (list of intervals)."
        if verbose >= DEBUG_LEXER:
            print "eval_polyrange(%s)" % self.line
        self.line = self.line.lstrip()
        polyrange_initials = (":","0","1","2","3","4","5","6","7","8","9","$", "@")
        if not self.peek() in polyrange_initials:
            polyrange = None
        else:
            selection = []
            while self.peek() in polyrange_initials + (".", ","):
                # First, literal command numbers (1-origin)
                match = re.match("[0-9]+", self.line)
                if match:
                    number = match.group()
                    selection.append(int(number)-1)
                    self.line = self.line[len(number):]
                    continue
                # Next, mark references
                match = re.match(":[0-9]+", self.line)
                if match:
                    markref = match.group()
                    self.line = self.line[len(markref):]
                    for (i, event) in enumerate(self.repo):
                        if hasattr(event, "mark") and event.mark == markref:
                            selection.append(i)
                            break
                        elif hasattr(event, "committish") and event.committish == markref:
                            selection.append(i)
                            break
                    else:
                        raise RecoverableException("mark %s not found." % markref)
                    continue
                # $ means last commit, a la ed(1).
                if self.peek() == "$":
                    selection.append(len(self.repo)-1)
                    self.pop()
                    continue
                # Comma just delimits a location spec
                if self.peek() == ",":
                    self.pop()
                    continue
                # Following ".." means a span
                if self.line[:2] == "..":
                    if selection:
                        selection.append("..")
                        self.line = self.line[2:]
                        continue
                    else:
                        raise RecoverableException("start of span is missing")
                if self.peek() == "@":
                    self.pop()
                    matched = False
                    # First, search branches
                    branchlist = list(self.repo.branches)
                    branchlist.sort(lambda x, y: len(x)-len(y)) # longest name first
                    for symbol in branchlist:
                        if self.line.startswith(os.path.basename(symbol)):
                            self.line = self.line[len(symbol):]
                            loc = None
                            # Find the last commit with this branchname
                            for (i, event) in enumerate(self.repo):
                                if isinstance(event, Commit):
                                    if event.branch == symbol:
                                        loc = i
                            if loc is None:
                                raise RecoverableException("branch name %s points to hyperspace" % symbol)
                            else:
                                matched = True
                                selection.append(loc)
                    # Next, search tags
                    taglist = filter(lambda e: isinstance(e, Tag), self.repo.events)
                    taglist.sort(lambda x, y: len(x.name)-len(y.name))
                    for tag in taglist:
                        if self.line.startswith(tag.name):
                            self.line = self.line[len(tag.name):]
                            for (i, event) in enumerate(self.repo):
                                if isinstance(event, Commit) and event.mark == tag.mark:
                                    matched = True
                                    selection.append(i)
                            else:
                                raise RecoverableException("tag name %s points to hyperspace" % tag.name)
                    if not matched:
                        raise RecoverableException("couldn't match a name at @%s" % self.line)
            if verbose >= DEBUG_LEXER:
                announce("location list is %s with %s left" % (selection, `self.line`))
            # Resolve spans
            resolved = []
            spanning = last = 0
            for elt in selection:
                if elt == '..':
                    spanning = True
                else:
                    if spanning:
                        resolved += range(last+1, elt+1)
                        spanning = False
                    else:
                        resolved.append(elt)
                    last = elt
            selection = resolved
            if verbose >= DEBUG_LEXER:
                announce("resolved list is %s with %s left" % (selection, `self.line`))
            # Sanity checks
            if spanning:
                raise RecoverableException("incomplete range expression.")
            for elt in selection:
                if elt < 0 or elt > len(self.repo)-1:
                    raise RecoverableException("event number %s out of range" % (elt+1))
            polyrange = set(selection)
        if verbose >= DEBUG_LEXER:
            print "%s <- eval_polyrange(), left = %s" % (polyrange, `self.line`)
        return polyrange
    def eval_textsearch(self):
        "Parse a text search specification."
        if verbose >= DEBUG_LEXER:
            print "eval_textsearch(%s)" % self.line
        self.line = self.line.lstrip()
        if not self.peek() == '/':
            textsearch = None
        elif '/' not in self.line[1:]:
            raise RecoverableException("malformed text search specifier")
        else:
            assert(self.pop() == '/')
            endat = self.line.index('/')
            regex = re.compile(self.line[:endat])
            self.line = self.line[endat+1:]
            matchers = []
            for (i, e) in enumerate(self.repo):
                # This catches commits and tags
                if hasattr(e, "comment") and regex.search(e.comment):
                    matchers.append(i)
                # And this catches passthroughs
                elif hasattr(e, "text") and regex.search(e.text):
                    matchers.append(i)
                # We don't do blobs because it would be too slow
                # and not very useful.
            if verbose >= DEBUG_LEXER:
                print "%s <- eval_textsearch(), left = %s" % (matchers, `self.line`)
            return set(matchers)
    def eval_branchset(self):
        "Resolve a branch name to its set of associated events."
        if self.peek() != "*":
            return None
        else:
            self.pop()
            branchlist = list(self.repo.branches)
            branchlist.sort(lambda x, y: len(x)-len(y)) # longest name first
            selection = []
            for symbol in branchlist:
                if self.line.startswith(os.path.basename(symbol)):
                    for (i, event) in enumerate(self.repo):
                        if isinstance(event, Reset):
                            if event.ref == symbol:
                                selection.append(i)
                        elif isinstance(event, Commit):
                            if event.branch == symbol:
                                selection.append(i)
                        elif isinstance(event, Tag):
                            ti = self.repo.find(event.committish)
                            assert(ti is not None)
                            assert(isinstance(self.repo[ti], Commit))
                            if self.repo[ti].branch == symbol:
                                selection.append(i)
                    self.line = self.line[len(os.path.basename(symbol)):]
                    break
            else:
                raise RecoverableException("unknown branch name %s" % self.line)
            return set(selection)
    #
    # Helpers
    #
    def report_select(self, line, method, optargs=()):
        "Generate a repository report on all objects with a specified method."
        if not self.repo:
            complain("no repo has been chosen.")
            return
        default = map(lambda x: x[0], filter(lambda (n, o): hasattr(o, method), enumerate(self.repo)))
        line = self.set_selection_set(line, default)
        outfile = line.strip()
        if outfile and outfile != '-':
            fp = open(outfile, "w")
        else:
            fp = sys.stdout
        for i in self.selection:
            event = self.repo.events[i]
            if hasattr(event, method):
                fp.write(getattr(event, method)(*((i,)+optargs)) + "\n")
        if outfile:
            fp.close()

    def uniquify(self, name):
        "Uniquify a repo name in the repo list."
        if name not in self.name_to_repo:
            return name
        else:
            # repo "foo" is #1
            seq = 2
            while name + str(seq) in self.name_to_repo:
                seq += 1
            return name + str(seq)
    #
    # On-line help and instrumentation
    #
    def help_help(self):
        print "Show help for a command. Follow with a space and the command name"
    def do_verbose(self, line):
        global verbose
        if line:
            try:
                verbose = int(line)
            except ValueError:
                print "reposurgeon: verbosity value must be an integer"
        if not line or verbose:
            announce("verbose %d" % verbose)
    def help_verbose(self):
        print """
Without an argument, this command requists a report of the verbosity
kevel.  'verbose 1' enables progress messages, 'verbose 0' disables
them. Higher levels of verbosity are available but intended for
developers only.
"""
    def do_echo(self, line):
        "Set or clear echoing commands before processing (for regression tests)"
        try:
            self.echo = int(line)
        except ValueError:
            announce("echo value must be an integer")
        if verbose:
            announce("echo %d" % self.echo)
    def do_version(self, line):
        "Report the program version and supported version-control systems."
        print "reposurgeon " + version + " supporting " + " ".join(map(lambda x: x.name, vcstypes))
    def do_resolve(self, line):
        "Display the set of event numbers generated by a section set."
        self.set_selection_set(line)
        if self.selection is None:
            print "No selection"
        elif type(self.selection) == type([]):
            print map(lambda x: x+1, self.selection)
        else:
            complain("resolve didn't expect a selection of %s" % self.selection)
    def help_resolve(self):
        print """
Does nothing but resolve a selection-set expression
and report the resulting event-number set to standard
output. Implemented mainly for recression testing, but may be useful
for exploring the selection-set language.
"""
    def do_names(self, line):
        "List all known symbolic names of branches and tags."
        for branch in self.repo.branches:
            print "branch %s" % branch
        for event in self.repo:
            if isinstance(event, Tag):
                print "tag    %s" % event.name
    def do_script(self, line):
        "Read and execute commands from a named file."
        if not line:
            complain("script requires a file argument")
            return
        try:
            for cmdline in open(line):
                interpreter.onecmd(interpreter.precmd(cmdline))
        except IOError:
            complain("failed to open script %s" % line)
    def do_history(self, line):
        "Dump your command list from this session so far."
        for line in self.history:
            print line
    def do_coverage(self, line):
        "Display the coverage-case set (developer instrumentation)."
        if not self.repo:
            complain("no repo has been chosen.")
            return
        for (i, e) in enumerate(self.repo.events):
            if isinstance(e, Commit):
                e.fileop_dump(i)
        coverage = list(self.repo.case_coverage)
        coverage.sort()
        print "Case coverage:", coverage
    #
    # Information-gathering
    #
    def do_stats(self, line):
        "Report on the chosen repository's information"
        if self.repo:
            def count(otype):
                return len(filter(lambda x: isinstance(x,otype), self.repo.events))
            print "Repository '%s' was read at %s" % (self.repo.name, iso8601_from_unixtime(self.repo.readtime))
            if self.repo.sourcedir:
                print "Loaded from", self.repo.sourcedir
            print "%.0fK, %d commands, %d blobs, %d commits, %d tags, %d resets, %d marks." % \
                  (self.repo.readsize / 1000.0, len(self.repo),
                   count(Blob), count(Commit), count(Tag), count(Reset),
                   self.repo.nmarks)
            if self.repo.vcs:
                print repr(self.repo.vcs)
        else:
            complain("no repository has been chosen.")
    def help_stats(self):
        print """
Report size statistics and import/export method information of the
currently chosen repository.
"""
    def do_index(self, line):
        "Generate a summary listing of objects."
        if not self.repo:
            complain("no repo has been chosen.")
            return
        # We could do all this logic using report_select() and index() methods
        # in the objects, but that would have two disavadntages.  First, we'd
        # get a default-set computation we don't want.  Second, for this
        # function it's helpful to have the method strings close together so
        # we can maintain columnation.
        default = map(lambda x: x[0], filter(lambda (n, o): not isinstance(o, Blob), enumerate(self.repo)))
        self.set_selection_set(line, default)
        for i in self.selection:
            event = self.repo.events[i]
            if isinstance(event, Blob):
                print "%6d blob   %6s    %s" % (i+1, event.mark,event.path)
                continue
            if isinstance(event, Commit):
                print "%6d commit %6s    %s" % (i+1, event.mark or '-', event.branch) 
                continue
            if isinstance(event, Tag):
                print "%6d tag    %6s    %4s" % (i+1, event.committish, `event.name`,) 
                continue
            if isinstance(event, Reset):
                print "%6d branch %6s    %s" % (i+1, event.committish or '-', event.ref) 
                continue
            else:
                print "?      -      %s" % (event,) 
    def help_index(self):
        print """
Display four columns of info on selected objects: their number, their
type, the associate mark (or '-' if no mark) and a summary field
varying by type.  For a branch or tag it's the reference; for a commit
it's the commit branch; for a blob it's the repository path of the
file in the blob.
"""
    def do_list(self, line):
        "Generate a human-friendly listing of objects."
        self.report_select(line, "lister", (screenwidth(),))
    def help_list(self):
        print """
Display commits in a human-friendly format; the first column is raw
event numbers, the second a timestamp, and the third the leading text
of the comment.  If there is a second argument, or the first is not
recognized as a selection set, it will be taken as the name of the
file to report to; no argument, or one of '-'; writes to standard
output.
"""
    #
    # Housekeeping
    #
    def do_prefer(self, line):
        "Report or select the preferred repository type."
        if line:
            for repotype in vcstypes:
                if line.lower() == repotype.name:
                    self.preferred = repotype
                    break
            else:
                complain("known types are %s.") % " ".join(map(lambda x: x.name, vcstypes))
        if verbose:
            if not self.preferred:
                announce("no preferred type has been set.")
            else:
                announce("%s is the preferred type." % self.preferred.name)
    def help_prefer(self):
        print """
Report or set (with argument) the preferred type of repository. This
will have two effects.  First, if there are multiple repositories in a
directory you do a read on, reposurgeon will read the preferred one
(otherwise it will complain that it can't choose among them).
Secondly, if you do a write to a directory, it will build a repo of
the preferred type.

If no preferred type has been explicitly selected, reading in a
repository (but not a fast-import stream) will implicitly set it
to the type of that repository.
"""
    def do_choose(self, line):
        "Choose a named repo on which to operate."
        if not self.name_to_repo:
            if verbose > 0:
                complain("no repositories are loaded.")
                return
        repolist = map(lambda n: (n, self.name_to_repo[n].readtime),
                       self.name_to_repo.keys())
        repolist.sort(lambda x, y: cmp(x[1], y[1]))
        if not line:
            for (name, readtime) in repolist:
                status =  '-'
                if self.repo and self.repo.name == name:
                    status = '*'
                print "%s %s %s" % (iso8601_from_unixtime(readtime), status, name)
        else:
            if line in self.name_to_repo:
                self.repo = self.name_to_repo[line]
                if verbose:
                    self.do_stats(line)
            else:
                complain("no such repo as %s" % line)
    def help_choose(self):
        print """
Choose a named repo on which to operate.  The name of a repo is
normally the basename of the directory or file it was loaded from, but
repos loaded from standard input are 'unnamed'. The program will add
a disambiguating suffix if there have been multiple reads from the
same source.

With no argument, lists the names of the currently stored repositories
and their load times.
"""
    def do_drop(self, line):
        "Drop a repo from reposurgeon's list."
        if not self.name_to_repo:
            if verbose:
                complain("no repositories are loaded.")
                return
        if not line:
            line = self.repo.name
        if line in self.name_to_repo:
            holdrepo = self.name_to_repo[line]
            holdrepo.cleanup()
            del self.name_to_repo[line]
            if line == self.repo.name:
                self.repo = None
            del holdrepo
        else:
            complain("no such repo as %s" % line)
        if verbose:
            # Emit listing of remaining repos
            self.do_choose('')
    def help_drop(self):
        print """
Drop a repo named by the argument from reposurgeon's list, freeing the memory
used for its metadata and deleting on-disk blobs. With no argument, drops the
currently chosen repo.
"""
    def do_rename(self, line):
        "Rename a repository."
        if line in self.name_to_repo:
            complain("there is already a repo named %s" % line)
        else:
            del self.name_to_repo[self.repo.name]
            self.name_to_repo[line] = self.repo
            self.repo.rename(line)
    def help_rename():
        print """
Rename the currently chosen repo; requires an argument.  Won't do it
if there is already one by the new name.
"""
    def do_preserve(self, line):
        "Add files and subdirectories to the preserve set."
        for filename in line.split():
            self.repo.preserve(filename)
        announce("preserving %s." % list(self.repo.preservable()))
    def help_preserve(self):
        print """
Add (presumably untracked) files or directories to the repo's list of
paths to be restored from the backup directory after a rebuild. Each
argument, if any, is interpreted as a pathname.  The current preserve
list is displayed afterwards.
"""
    def do_unpreserve(self, line):
        "Remove files and subdirectories from the preserve set."
        for filename in line.split():
            self.repo.unpreserve(filename)
        announce("preserving %s." % list(self.repo.preservable()))
    def help_unpreserve(self):
        print """
Remove (presumably untracked) files or directories to the repo's list
of paths to be restored from the backup directory after a
rebuild. Each argument, if any, is interpreted as a pathname.  The
current preserve list is displayed afterwards.
"""
    #
    # Serialization and de-serialization.
    #
    def do_read(self, line):
        "Read in a repository for surgery."
        self.preferred = None
        if line:
            line = os.path.expanduser(line)
        if not line or line == '.':
            line = os.getcwd();
        self.repo = read_repo(line, self.preferred)
        if self.repo:
            if self.repo.vcs:
                self.preferred = self.repo.vcs.name
            name = self.uniquify(os.path.basename(self.repo.sourcedir or line or "unnamed"))
            self.repo.rename(name)
            self.name_to_repo[name] = self.repo
        if verbose:
            self.do_choose('')
    def help_read(self):
        print """
A read command with no arguments is treated as 'read .', operating on the
current directory.
 
With a directory-name argument, this command attempts to read in the
contents of a repository in any supported version-control system under
that directory.

If the argument is the name of a plain file, it will be read in as a
fast-import stream.

With an argument of <quote>-</quote>, this command reads a fast-import
stream from standard input (this will be useful in filters constructed
with command-line arguments).
"""
    def do_write(self, line):
        "Stream out the results of repo surgery."
        if not self.repo:
            complain("no repo has been chosen.")
            return
        line = self.set_selection_set(line, range(len(self.repo)))
        if not line:
            line = '-'
        if line == '-':
            self.repo.fast_export(self.selection, sys.stdout, progress=verbose>0)
        else:
            try:
                with open(line, "w") as out:
                    self.repo.fast_export(self.selection, out)
            except OSError:
                complain("open of %s for write failed.\n" % line)
    def help_write(self):
        print """
Dump a fast-import stream representing selected events to standard output
(if second argument is empty or '-') or a file.  Fails if the argument exists
and is a directory or anything other than a plain file. The default selection
is all events.
"""
    def do_inspect(self, line):
        "Dump raw events."
        if not self.repo:
            complain("no repo has been chosen.")
            return
        self.set_selection_set(line, range(len(self.repo)))
        for ei in self.selection:
            sys.stdout.write(`ei+1` + ": " + (72 * "=") + "\n") 
            sys.stdout.write(str(self.repo[ei]))
    def help_inspect(self):
        print """
Dump a fast-import stream representing selected events to standard output.
Just like a write, except the progress meter is disabled and there is
a header identifying the event before each commit.
"""
    def do_rebuild(self, line):
        "Rebuild a repository from the edited state."
        if not self.repo:
            complain("no repo has been chosen.")
            return
        rebuild_repo(self.repo, line, self.preferred)
    def help_rebuild(self):
        print """
Rebuild a repository from the state held by reposurgeon.  The argument
specifies the target directory in which to do the rebuild; if the
repository read was from a repo directory (and not a git-import stream), it
defaults to that directory.  If the target directory is nonempty
its contents are backed up to a save directory.
"""
    #
    # Editing commands
    #
    def do_mailbox_out(self, line):
        "Generate a mailbox file representing object metadata."
        self.report_select(line, "email_out")
    def help_mailbox_out(self):
        print """
Emit a mailbox file of messages in RFC822 format representing the
contents of repository metadata. Takes a selection set; members of the set
other than commits, annotated tags, and passthroughs are ignored (that
is, presently, blobs and resets).  If there is a second argument, or
the first is not recognized as a selection set, it will be taken as
the name of the file to report to; no argument, or one of '-'; writes
to standard output.
"""
    def do_mailbox_in(self, line):
        "Accept a mailbox file representing object metadata and update from it."
        infile = line.strip()
        if infile and infile != '-':
            fp = open(infile)
        else:
            fp = sys.stdin
        update_list = []
        while True:
            msg = RepoSurgeonEmail.readmsg(fp)
            if not msg:
                break
            update_list.append(email.message_from_string(msg))
        if infile:
            fp.close()
        # First, a validation pass
        for (i, message) in enumerate(update_list):
            if "Event-Number" not in message:
                raise RepoSurgeonError("missing event number in update %d" % i)
            eventnum = int(message["Event-Number"]) - 1
            if eventnum < 0 or eventnum >= len(self.repo):
                raise FatalException("event number %d out of range in update %d" % (eventnum, i+1))
            event = self.repo[eventnum]
            if not hasattr(event, "email_in"):
                raise FatalException("event %d cannot be modified" % (eventnum+1,))
        # Now apply the updates
        modified = []
        for update in update_list:
            eventnum = int(update["Event-Number"]) - 1
            event = self.repo[eventnum]
            if event.email_in(update):
                modified.append(eventnum+1)
        if verbose:
            if not modified:
                announce("no events modified.")
            else:
                announce("modified events are %s." % (modified,))

    def help_mailbox_in(self):
        print """
Accept a mailbox file of messages in RFC822 format representing the
contents of the metadata in selected commits and annotated tags. Takes
no selection set.  If there is an argument it will be taken as the
name of a mailbox file to read from; no argument, or one of '-'; reads
from standard output.

Users should be aware that modifying an Event-Number field will change
which event the update from that message is applied to.  This is
unlikely to have good results.

Event updates are atomic; if reposurgeon throws an error while in this
command events updated before the error will keep their changed state,
but no event will be partially modified. Event numbers are validated
before any individual event is updated.

At present only the comment fields of commits and tags are updated from
the mailbox contents; commit and tag metadata cannot be altered. This
may change in a future release.
"""
    def do_edit(self, line):
        "Edit metadata interactively."
        if not self.repo:
            complain("no repo is loaded")
            return
        default = map(lambda x: x[0], filter(lambda (n, o): hasattr(o, "email_out"), enumerate(self.repo)))
        line = self.set_selection_set(line, default)
        editor = line or os.getenv("EDITOR")
        if not editor:
            complain("you have not specified an editor and $EDITOR is not set")
            return
        # Special case: user selected a single blob
        if len(self.selection) == 1:
            singleton = self.repo[self.selection[0]]
            if isinstance(singleton, Blob):
                def find_successor(event, path):
                    here = []
                    for child in event.children():
                        for fileop in child.fileops:
                            if fileop.op == "M" and fileop.path == path:
                                here.append(child.mark)
                        here += find_successor(child, path)
                    return here 
                blobfile = singleton.blobfile()
                for event in self.repo.commits():
                    for fileop in event.fileops:
                        if fileop.op == 'M' and fileop.ref == singleton.mark:
                            if len(find_successor(event, fileop.path)) > 0:
                                complain("beware: not the last 'M %s' on its branch" % fileop.path)
                            break
                os.system(editor + " " + blobfile)
                return
            # Fall through
        # Otherwise, mailboxize and edit the non-blobs in the selection
        try:
            (tfdesc, tfname) = tempfile.mkstemp()
            with open(tfname, "w") as tfp:
                for i in self.selection:
                    event = self.repo[i]
                    if hasattr(event, "email_out"):
                        tfp.write(event.email_out(i))
            if os.system(editor + " " + tfname):
                raise RecoverableException("%s returned a failure status" % editor)
            else:
                self.do_mailbox_in(tfname)
        finally:
            os.remove(tfname)
    def help_edit(self):
        print """
Report the selection set of events to a tempfile as mailbox_out does,
call an editor on it, and update from the result as mailbox_in does.
If you do not specify an editor name as second argument, it will be
taken from the $EDITOR variable in your environment.

Normally this command ignores blobs because mailbox_out does.
However, if you specify a selection set consisting of a single
blob, your editor will be called on the blob file.
"""
    def do_delete(self, line):
        "Delete events in the specified selection set."
        if not self.repo:
            complain("no repo is loaded")
            return
        line = self.set_selection_set(line, [])
        if line and not hasattr(self.repo, "policy_" + line):
            complain("no such deletion policy as " + `line`)
            return
        self.repo.delete(self.selection, self.line)
    def help_delete(self):
        print """
Delete a selection set of commits (and their associated blobs, if
any).  The default selection set for this command is empty.  Tags
pointing at the commits are also removed.

Note that applying this command to a commit with a modify operation
will *not* necessarily remove changes made by that commit from later
versions.  It will have the effect of retracting the modifications
only when they are the final ones on the commit's branch.
"""
    def do_coalesce(self, line):
        "Coalesce events in the specified selection set."
        if not self.repo:
            complain("no repo is loaded")
            return
        line = self.set_selection_set(line, [])
        if not line:
            timefuzz = 90
        else:
            try:
                timefuzz = int(line)
            except ValueError:
                raise RepoSurgeonError("time-fuzz value must be an integer")
        eligible = []
        # This is a crude search that ignores the repo graph structure;
        # properly speaking we should be chasing child links.  Screw
        # it; this operation only make sense for cleaning up
        # artifacts in linear stretches of history that have been
        # lifted from file-oriented VCSes like RCS and CVS.
        commits = filter(lambda (i, e): isinstance(e, Commit),
                         enumerate(self.repo))
        for i in range(len(commits)-1):
            this = self.repo.events[commits[i][0]]
            next = self.repo.events[commits[i+1][0]]
            if not (isinstance(this, Commit) and isinstance(next, Commit)):
                continue
            elif this.branch != next.branch:
                continue
            elif this.comment != next.comment:
                continue
            elif this.committer.date.delta(next.committer.date) < timefuzz:
                eligible.append(commits[i][0])
        if verbose:
            announce("deletion set is %s" % map(lambda x: x+1, eligible))
        self.repo.delete(eligible, "coalesce")
    def help_coalesce(self):
        print """
Scan the selection set for runs of commits with identical
comments close to each other in time (this is a common form of scar
tissues in repository up-conversions from older file-oriented
version-control systems).  Merge these cliques by deleting all but the
last commit, in order.

The optional second argument, if present, is a maximum time
separation in seconds; the default is 90 seconds.
"""
    def do_timeoffset(self, line):
        "Apply a time offset to all dates in selected events."
        if not self.repo:
            complain("no repo has been chosen.")
            return
        line = self.set_selection_set(line, range(len(self.repo)))
        if not line:
            complain("a signed time offset argument is required.")
            return
        elif not line[0] in ('-', '+'):
            complain("time offset argument must begin with + or -.")
            return
        args = line.split()
        h = m = "0"
        if args[0].count(":") == 0:
            s = args[0]
        elif args[0].count(":") == 1:
            (m, s) = args[0].split(":")
        elif args[0].count(":") == 2:
            (h, m, s) = args[0].split(":")
        else:
            complain("too many colons")
            return
        try:
            offset = int(h)*360 + int(m)*60 + int(s)
        except ValueError:
            complain("expected numeric literals in date format")
            return
        if len(args) > 1:
            if not re.match("[+-][0-9][0-9][0-9][0-9]", args[1]):
                complain("expected timezone literal to be [+-]hhmm")
        for ei in self.selection:
            event = self.repo[ei]
            if isinstance(event, Tag):
                if event.tagger:
                    event.tagger.unixtime += offset
                    if len(args) > 1:
                        event.tagger.timezone = args[1]
            elif isinstance(event, Commit):
                event.committer.unixtime += offset
                if len(args) > 1:
                    event.committer.timezone = args[1]
                for author in event.authors:
                    author.unixtime += offset
                    if len(args) > 1:
                        author.timezone = args[1]
    def help_timeoffset(self):
        print """
Apply a time offset to all time/date stamps in the selected set.  An offset
argument is required; it may be in the form [+-]ss, [+-]mm:ss or [+-]hh:mm:ss.
The leading sign is required to distingush it from a selection expression.

Optionally you may also specify another argument in the form [+-]hhmm, a
timeone literal to apply.  To apply a timezone without an offset, use
an offset literal of +0 or -0.
"""
    def do_cut(self, line):
        "Attempt to topologically partition the repo."
        if not self.repo:
            complain("no repo has been chosen.")
            return
        line = self.set_selection_set(line, [])
        if len(self.selection) == 0:
            complain("one or possibly two arguments specifying a link are required")
            return
        early = self.repo[self.selection[0]]
        possibles = early.children() 
        if len(self.selection) == 1:    
            if len(possibles) > 1:
                complain("commit has multiple children, one must be specified")
                return
            elif len(possibles) == 1:
                possibles = early.children()
                late = possibles[0]
            else:
                complain("parent has no children")
                return
        elif len(self.selection) == 2:
            late = self.repo[self.selection[1]]
            if early.mark not in late.parent_marks:
                complain("not a parent-child pair")
                return
        elif len(self.selection) > 2:
            complain("too many arguments")
        assert(early and late)
        # Graph-coloring algorithm to determine if the repo can be split
        wherein = late.parent_marks.index(early.mark)
        late.parent_marks.remove(early.mark)
        def do_color(commit, color):
            commit.color = color
            for fileop in commit.fileops:
                if fileop.op == "M" and fileop.ref != "inline":
                    blob = self.repo.find(fileop.ref)
                    assert isinstance(self.repo[blob], Blob)
                    self.repo[blob].color = color
        do_color(early, "early")
        do_color(late, "late")
        conflict = False
        keepgoing = True
        visited = [False] * len(self.repo.commits())
        while keepgoing and not conflict:
            keepgoing = False
            for (i, event) in enumerate(self.repo.commits()):
                if event.color and not visited[i]:
                    visited[i] = True
                    for neighbor in event.parents() + event.children():
                        if neighbor.color == None:
                            do_color(neighbor, event.color)
                            keepgoing = True
                            break
                        elif neighbor.color != event.color:
                            conflict = True
                            break
        if conflict:
            complain("repository cannot be split here")
            late.parent_marks.push(early.mark, where)
            for event in self.repo:
                if hasattr(event, "color"):
                    event.color = None
            return
        assert all(map(lambda x: hasattr(x, "color") or isinstance(x, Reset), self.repo))
        # Repo can be split, so we need to color tags
        for t in self.repo.events:
            if isinstance(t, Tag):
                for c in self.repo.events:
                    if isinstance(c, Commit):
                        if c.mark == t.committish:
                            t.color = c.color
        # Resets are tricky.  One may have both colors.
        trackbranches = {"early": set([]), "late": set([])}
        for commit in self.repo.commits():
            trackbranches[commit.color].add(commit.branch)
        # Now it's time to do the actual partitioning
        early = Repository()
        late = Repository()
        for event in self.repo:
            if isinstance(event, Reset):
                if event.ref in trackbranches["early"]:
                    early.events.append(copy.copy(event))
                if event.ref in trackbranches["late"]:
                    late.events.append(copy.copy(event))
            else:
                if event.color == "early":
                    event.repo = early
                    early.events.append(event)
                elif event.color == "late":
                    event.repo = late
                    late.events.append(event)
                else:
                    raise FatalException("coloring algorithm failed on %s" % event)
        # Add the split results to the name table. 
        early.name = self.repo.name + "-early" 
        self.name_to_repo[early.name] = early
        early.readtime = time.time()
        late.name = self.repo.name + "-late"
        self.name_to_repo[late.name] = late
        late.readtime = time.time()
        del self.name_to_repo[self.repo.name]
        self.repo.cleanup()
        del self.repo
        self.repo = None
    def help_cut(self):
        print """
Attempt to partition a repo by cutting the parent-child link
between two specified commits (they must be adjacent). Does not take a
general selection-set argument.  It is only necessary to specify the
parent commit, unless it has multiple children in which case the child
commit must follow.

This operation may fail if the commit graph remains connected
through another path; the tool will detect this. If the repo was named
'foo', the cut segments will be named 'foo-early' and 'foo-late'.
"""
    def do_expunge(self, line):
        "Expunge files from the chosen repository."
        if not self.repo:
            complain("no repo has been chosen.")
            return
        line = self.set_selection_set(line, range(len(self.repo)))
        def digest(toklist):
            return re.compile("|".join(map(lambda s: "(?:" + s + ")", toklist)))
        matchers = line.split()
        try:
            expunge = digest(matchers)
            modified = []
            for ei in self.selection:
                event = self.repo[ei]
                if hasattr(event, "fileops"):
                    deletia = []
                    for (i, fileop) in enumerate(event.fileops):
                        if verbose >= DEBUG_DELETE:
                            print str(fileop)
                        if fileop.op in "DM":
                            if expunge.search(fileop.path):
                                deletia.append(i)
                                if fileop.op == 'M':
                                    if fileop.ref == 'inline':
                                        os.remove(os.path.join(self.repo.subdir(), fileop.copyname))
                                    else:
                                        bi = self.repo.find(fileop.ref)
                                        assert(isinstance(self.repo[bi], Blob))
                                        self.repo[bi].release()
                                    if verbose:
                                        announce("at %d, deleting %s" % (ei+1, fileop.path))
                        elif fileop.op in "RC":
                            if expunge.search(fileop.source):
                                deletia.append(i)
                                complain("following %s of %s to %s" %
                                         (fileop.op,
                                          fileop.source,
                                          fileop.target))
                                if fileop.op == "R" and file.source in matchers:
                                    matchers.remove(fileop.source)
                                matchers.append("^" + fileop.target + "$")
                                expunge = digest(matchers)
                            elif expunge.search(fileop.target):
                                if fileop.op == "R":
                                    fileop.op = "D"
                                elif fileop.op == "C":
                                    deletia.append(i)
                                matchers.append("^" + fileop.target + "$")
                                expunge = digest(matchers)
                    if deletia:
                        deletia.reverse()
                        for i in deletia:
                            event.fileops.pop(i)
        except re.error:
            raise FatalException("you confused the regular-expression processor.")
        # Now remove commits that no longer have fileops, and released blobs.
        deletia = map(lambda e: not ((isinstance(e, Commit) and len(e.fileops)==0) or (isinstance(e, Blob) and not e.path)), self.repo.events)
        deletia = map(lambda x: x[0], filter(lambda (i, e): not e, enumerate(deletia)))
        if verbose:
            announce("deleting blobs and empty commits %s" % map(lambda x: x+1, deletia))
            deletia.reverse()
            for i in deletia:
                self.repo.events.pop(i)
    def help_expunge(self):
        print """
Expunge files from the selected portion of the repo history; the
default is the entire history.  The arguments to this command may be
paths or Python regular expressions matching paths.

All filemodify (M) operations and delete (D) operations involving a
matched file in the selected set of events are removed.  Renames are
followed as the tool walks forward in the selection set; each triggers
a warning message. If a selected file is a copy (C) target, the copy
will be deleted and a warning message issued. If a selected file is a
copy source, the copy target will be added to the list of paths to be
deleted and a warning issued.

After file expunges have been performed, any commits with no
remaining file operations will be deleted, and any tags pointing to
them.
"""
    def do_split(self, line):
        "Split a commit."
        if not self.repo:
            raise RecoverableException("no repo has been chosen.")
            return
        line = self.set_selection_set(line, [])
        if len(self.selection) != 1:
            raise RecoverableException("selection of a single commit required for this command")
            return
        where = self.selection[0]
        event = self.repo[where]
        if not isinstance(event, Commit):
            raise RecoverableException("fileop argument doesn't point at a commit")
            return
        if not line.startswith("at"):
            raise RecoverableException("expected 'at'")
            return
        else:
            line = line[2:].lstrip()
            try:
                splitpoint = int(line.split()[0]) - 1
            except ValueError:
                raise RecoverableException("expected integer fileop index (1-origin)")
            if splitpoint not in range(1, len(event.fileops)):
                raise RecoverableException("fileop index out of range")
            # Actual implementation starts here
            self.repo.events.insert(where+1, copy.deepcopy(event))
            event2 = self.repo.events[where+1]
            assert(event.mark == event2.mark)
            event2.mark = event.mark + "bis"
            # Fix up parent/child relationships
            event2.parent_marks = [event.mark]
            for child in event.children():
                for (j, mark) in enumerate(child.parent_marks):
                    if mark == event.mark:
                        child.parent_marks[j] == event2.mark
            # Fileop split happens here
            event2.fileops = event.fileops[splitpoint:]
            event.fileops = event.fileops[:splitpoint]
            if verbose:
                self.do_inspect(`where+1`+","+`where+2`)
    def help_split(self):
        print """
Split a specified commit in two, the opposite of coalesce.  The first argument
is required to be a commit location; the separating keyword 'at' must follow,
then an integer 1-origin index of a file operation within the commit.

The commit is copied copied and inserted into a new position in the
event sequence, immediately following itself; the duplicate becomes
the child of the original, and replaces it as parent of the original's
children. Commit metadata is duplicated; the mark of the new commit is
then changed, with 'bis' added as a suffix.

Finally, some file operations - starting at the one indexed by the split
argument - are moved forward from the original commit into the new one.
Legal indices are 2-n, where n is the number of file operations in the
original commit.
"""
    def do_merge(self, line):
        "Merge repos together."
        self.repo = None
        factors = []
        for name in line.split():
            repo = self.name_to_repo.get(name)
            if repo is None:
                raise RecoverableException("no such repo as %s" % name)
            else:
                factors.append(repo)
        factors.sort(lambda x, y: cmp(x.earliest(), y.earliest()))
        roots = map(lambda x: x.commits()[0], factors)
        union = Repository()
        union.name = "+".join(map(lambda r: r.name, factors))
        union.readtime = time.time()
        marklist = []
        os.mkdir(union.subdir())
        for (i, factor) in enumerate(factors):
            # Only vcstype, sourcedir, and basedir are not copied here
            union.readsize += factor.readsize
            union.nmarks += factor.nmarks
            union.branches |= factor.branches
            union.import_line += factor.import_line
            union.preserve_set |= factor.preserve_set
            union.case_coverage |= factor.case_coverage
            del self.name_to_repo[factor.name]
            for event in factor.events:
                # Reparent all objects with pointers upwards to the union
                if hasattr(event, "repo"):
                    event.repo = union
                # Disambiguate branches and tags
                if i != 0:
                    prefix = factor.name + "-"
                    for (type, attr) in ((Tag, "name"),):
                        if isinstance(event, type):
                            setattr(event, attr, prefix + getattr(event, attr))
                    suffix = "-" + factor.name
                    for (type, attr) in ((Commit, "branch"),
                                         (Reset, "ref")):
                        if isinstance(event, type):
                            setattr(event, attr, getattr(event, attr) + suffix)
                # Disambiguate all marks.
                for fld in ("mark", "committish"):
                    if hasattr(event, fld):
                        old = getattr(event, fld)
                        if old is None:
                            continue
                        elif not old.startswith(":"):
                            raise FatalException("field not in mark format")
                        else:
                            new = old + factor.name
                            if verbose >= DEBUG_MERGE:
                                announce("moving %s -> %s in %s"
                                         % (old, new, fld))
                            setattr(event, fld, new)
                            marklist.append(new)
                if isinstance(event, Commit):
                    for (j, old) in enumerate(event.parent_marks):
                        new = old + factor.name
                        if verbose >= DEBUG_MERGE:
                            announce("moving %s -> %s in parents" % (old, new))
                        event.parent_marks[j] = new
                    for fileop in event.fileops:
                        if fileop.op == "M" and fileop.ref.startswith(":"):
                            new = fileop.ref + factor.name
                            if verbose >= DEBUG_MERGE:
                                announce("moving %s -> %s in fileop"
                                         % (fileop.ref, new))
                            fileop.ref = new
                            marklist.append(new)
            # Merge in the events and blobs
            union.events += factor.events
            for blobfile in os.listdir(factor.subdir()):
                os.rename(os.path.join(factor.subdir(), blobfile),
                          os.path.join(union.subdir(), blobfile))
            factor.events = []
            factor.cleanup()
            #del factor
        # Sort all events by imputed timestamp
        union.events.sort(lambda x,y: cmp(x.when(), y.when()))
        # Renumber the marks:
        for event in union.events:
            for fld in ("mark", "committish"):
                if hasattr(event, fld) and getattr(event, fld):
                    old = getattr(event, fld)
                    new = ":" + `1 + marklist.index(old)`
                    if verbose >= DEBUG_MERGE:
                        announce("renumbering %s -> %s in %s" % (old, new,fld))
                    setattr(event, fld, new)
            if isinstance(event, Commit):
                for (i, old) in enumerate(event.parent_marks):
                    new = ':' + `1 + marklist.index(old)`
                    if verbose >= DEBUG_MERGE:
                        announce("renumbering %s -> %s in parents" % (old, new))
                    event.parent_marks[i] = new
                for fileop in event.fileops:
                    if fileop.op == "M" and fileop.ref.startswith(":"):
                        new = ":" + `1 + marklist.index(fileop.ref)`
                        if verbose >= DEBUG_MERGE:
                            announce("renumbering %s -> %s in fileop" % (fileop.ref, new))
                        fileop.ref = new
        # Sort out the root grafts. All but the first get glued to the
        # previous commit closest in time.
        lastcommit = None
        for commit in union.commits():
            if commit != roots[0] and not commit.parent_marks:
                if not lastcommit:
                    raise FatalException("can't find previous commit to link")
                if lastcommit.mark is None:
                    raise FatalException("can't link to commit with no mark")
                commit.parent_marks.append(lastcommit.mark)
            lastcommit = commit
        # Put the result on the load list
        self.name_to_repo[union.name] = union
        self.repo = union
        if verbose:
            self.do_choose('')
    def help_merge(self):
        print """
Merge repositories. Name any number of loaded repositories; they will
be merged into one union repo and removed from the load list.  The
union repo will be selected.

Before merging, the repos will be sorted by date of first commit.  The
oldest will keep all its branch and tag names unchanged (this rule is
followed so there will always be a defined default branch).  All others
will have their branch and tag names suffixed with their load name.
Marks will be renumbered.

The name of the new repo will be the names of all parts concatenated,
separated by '+'. It will have no source directory or preferred system
type.
"""

if __name__ == '__main__':
    try:
        interpreter = RepoSurgeon()
        interpreter.use_rawinput = False
        if not sys.argv[1:]:
            sys.argv.append("-")
        try:
            for arg in sys.argv[1:]:
                for arg in arg.split(";"):
                    if arg == '-':
                        interpreter.use_rawinput = True
                        if verbose == 0:
                            verbose = 1
                        interpreter.cmdloop()
                        interpreter.use_rawinput = False
                    else:
                        # Call the base method so RecoverableExceptios
                        # won't be caught; we want them to abort scripting.
                        cmd.Cmd.onecmd(interpreter, interpreter.precmd(arg))
        finally:
            interpreter.cleanup()
        raise SystemExit, 0
    except (RecoverableException, FatalException), e:
        complain(e.msg)
        raise SystemExit, 1
    except KeyboardInterrupt:
        print ""
# end
